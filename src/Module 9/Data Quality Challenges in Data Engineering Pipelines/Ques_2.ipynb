{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Handling Schema Mismatches using Spark\n",
    "**Description**: Use Apache Spark to address schema mismatches by transforming data to match\n",
    "the expected schema.\n",
    "\n",
    "**Steps**:\n",
    "1. Create Spark session\n",
    "2. Load dataframe\n",
    "3. Define the expected schema\n",
    "4. Handle schema mismatches\n",
    "5. Show corrected data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PySpark not available. Spark functionality skipped.\n",
      "Raw Ingested Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>API</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>API</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>API</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>None</td>\n",
       "      <td>API</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>API</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  amount transaction_date source\n",
       "0          1.0   100.0       2024-01-01    API\n",
       "1          2.0     NaN       2024-01-02    API\n",
       "2          NaN   200.0       2024-01-03    API\n",
       "3          4.0   300.0             None    API\n",
       "4          5.0     NaN       2024-01-05    API"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema validation successful.\n",
      "Missing Value Report:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Count</th>\n",
       "      <th>Missing %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>customer_id</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amount</th>\n",
       "      <td>2</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transaction_date</th>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Missing Count  Missing %\n",
       "customer_id                   1       20.0\n",
       "amount                        2       40.0\n",
       "transaction_date              1       20.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Data:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11667/1800378811.py:74: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['amount'].fillna(df_cleaned['amount'].mean(), inplace=True)  # Impute amount\n",
      "/tmp/ipykernel_11667/1800378811.py:75: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_cleaned['transaction_date'].fillna(method='ffill', inplace=True)  # Fill forward dates\n",
      "/tmp/ipykernel_11667/1800378811.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_cleaned['transaction_date'].fillna(method='ffill', inplace=True)  # Fill forward dates\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>amount</th>\n",
       "      <th>transaction_date</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>API</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>API</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>API</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>API</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  amount transaction_date source\n",
       "0          1.0   100.0       2024-01-01    API\n",
       "1          2.0   200.0       2024-01-02    API\n",
       "3          4.0   300.0       2024-01-02    API\n",
       "4          5.0   200.0       2024-01-05    API"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.003s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Unit Tests...\n",
      "Cleaned data saved to cleaned_output.csv\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import unittest\n",
    "\n",
    "# Optional: Spark setup\n",
    "try:\n",
    "    from pyspark.sql import SparkSession\n",
    "    from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType\n",
    "    from pyspark.sql.functions import col\n",
    "    spark = SparkSession.builder.appName(\"DQ_Task_Q2\").getOrCreate()\n",
    "    spark_available = True\n",
    "except ImportError:\n",
    "    print(\"PySpark not available. Spark functionality skipped.\")\n",
    "    spark_available = False\n",
    "\n",
    "# Step 2: Define a custom exception for validation errors\n",
    "class DataValidationError(Exception):\n",
    "    \"\"\"Custom exception for data validation errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "# Step 3: Define function to load CSV safely\n",
    "def load_csv_safe(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading CSV: {str(e)}\")\n",
    "\n",
    "# Step 4: Simulate ingestion with missing values\n",
    "data = {\n",
    "    'customer_id': [1, 2, np.nan, 4, 5],\n",
    "    'amount': [100.0, None, 200.0, 300.0, None],\n",
    "    'transaction_date': ['2024-01-01', '2024-01-02', '2024-01-03', None, '2024-01-05']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Add a new column for the data source\n",
    "df['source'] = 'API'\n",
    "\n",
    "print(\"Raw Ingested Data:\")\n",
    "display(df)\n",
    "\n",
    "# Step 5: Schema validation\n",
    "required_cols = ['customer_id', 'amount', 'transaction_date', 'source']\n",
    "def check_schema(df, required_cols):\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            raise DataValidationError(f\"Missing expected column: {col}\")\n",
    "    if not np.issubdtype(df['customer_id'].dropna().dtype, np.number):\n",
    "        raise TypeError(\"customer_id must be numeric\")\n",
    "\n",
    "try:\n",
    "    check_schema(df, required_cols)\n",
    "    print(\"Schema validation successful.\")\n",
    "except Exception as e:\n",
    "    print(f\"Schema validation failed: {e}\")\n",
    "\n",
    "# Step 6: Report missing values\n",
    "def missing_report(df):\n",
    "    report = df.isnull().sum().to_frame('Missing Count')\n",
    "    report['Missing %'] = (report['Missing Count'] / len(df)) * 100\n",
    "    return report[report['Missing Count'] > 0]\n",
    "\n",
    "print(\"Missing Value Report:\")\n",
    "display(missing_report(df))\n",
    "\n",
    "# Step 7: Handle missing values\n",
    "def clean_missing_data(df):\n",
    "    df_cleaned = df.dropna(subset=['customer_id'])  # Drop rows with missing IDs\n",
    "    df_cleaned['amount'].fillna(df_cleaned['amount'].mean(), inplace=True)  # Impute amount\n",
    "    df_cleaned['transaction_date'].fillna(method='ffill', inplace=True)  # Fill forward dates\n",
    "    return df_cleaned\n",
    "\n",
    "df_clean = clean_missing_data(df)\n",
    "print(\"Cleaned Data:\")\n",
    "display(df_clean)\n",
    "\n",
    "# Step 8: Simulate schema mismatch in PySpark (optional)\n",
    "if spark_available:\n",
    "    print(\"Simulating Spark schema mismatch:\")\n",
    "    try:\n",
    "        schema = StructType([\n",
    "            StructField(\"customer_id\", IntegerType(), True),\n",
    "            StructField(\"amount\", DoubleType(), True),\n",
    "            StructField(\"transaction_date\", StringType(), True)\n",
    "        ])\n",
    "        # Simulated bad input\n",
    "        bad_data = [(\"1\", \"invalid_amount\", \"2024-01-01\")]\n",
    "        spark_df = spark.createDataFrame(bad_data, schema=schema)\n",
    "        spark_df.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Spark schema mismatch error handled: {e}\")\n",
    "\n",
    "# Step 9: Unit tests\n",
    "class TestMissingValueHandling(unittest.TestCase):\n",
    "\n",
    "    def test_amount_imputation(self):\n",
    "        test_df = pd.DataFrame({'amount': [100.0, None, 200.0]})\n",
    "        mean_val = test_df['amount'].mean()\n",
    "        test_df['amount'].fillna(mean_val, inplace=True)\n",
    "        self.assertEqual(test_df.isnull().sum().sum(), 0)\n",
    "\n",
    "    def test_drop_missing_ids(self):\n",
    "        test_df = pd.DataFrame({'customer_id': [1, None, 3]})\n",
    "        df_cleaned = test_df.dropna(subset=['customer_id'])\n",
    "        self.assertEqual(len(df_cleaned), 2)\n",
    "\n",
    "print(\"Running Unit Tests...\")\n",
    "unittest.main(argv=[''], exit=False)\n",
    "\n",
    "# Step 10: Save cleaned data\n",
    "df_clean.to_csv(\"cleaned_output.csv\", index=False)\n",
    "print(\"Cleaned data saved to cleaned_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Detect and Correct Incomplete Data in ETL\n",
    "**Description**: Use Python and Pandas to detect incomplete data in an ETL process and fill\n",
    "missing values with estimates.\n",
    "\n",
    "**Steps**:\n",
    "1. Detect incomplete data\n",
    "2. Fill missing values\n",
    "3. Report changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code from here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
