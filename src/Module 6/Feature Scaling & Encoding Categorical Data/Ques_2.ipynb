{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Question 5: Label Encoding vs One-Hot Encoding ---\n",
      "Label Encoded 'sex': [1 0 0 0 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7382/1660965201.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['age'].fillna(df['age'].median(), inplace=True)\n",
      "/tmp/ipykernel_7382/1660965201.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel Encoded \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sex_label_encoded[:\u001b[38;5;241m5\u001b[39m])\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# One-Hot Encoding for 'sex'\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m ohe \u001b[38;5;241m=\u001b[39m \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mif_binary\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m sex_onehot_encoded \u001b[38;5;241m=\u001b[39m ohe\u001b[38;5;241m.\u001b[39mfit_transform(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne-Hot Encoded \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, sex_onehot_encoded[:\u001b[38;5;241m5\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Load Titanic dataset from seaborn\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# For simplicity, fill missing ages with median for these tasks\n",
    "df['age'].fillna(df['age'].median(), inplace=True)\n",
    "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
    "\n",
    "print(\"\\n--- Question 5: Label Encoding vs One-Hot Encoding ---\")\n",
    "# Label Encoding for 'sex'\n",
    "le = LabelEncoder()\n",
    "sex_label_encoded = le.fit_transform(df['sex'])\n",
    "print(\"Label Encoded 'sex':\", sex_label_encoded[:5])\n",
    "\n",
    "# One-Hot Encoding for 'sex'\n",
    "ohe = OneHotEncoder(sparse=False, drop='if_binary')\n",
    "sex_onehot_encoded = ohe.fit_transform(df[['sex']])\n",
    "print(\"One-Hot Encoded 'sex':\\n\", sex_onehot_encoded[:5])\n",
    "\n",
    "print(\"\\n--- Question 6: Combining Feature Scaling Techniques ---\")\n",
    "features = df[['age', 'fare']].copy()\n",
    "\n",
    "# Min-Max Scaling\n",
    "minmax_scaler = MinMaxScaler()\n",
    "features_minmax = minmax_scaler.fit_transform(features)\n",
    "\n",
    "# Standardization\n",
    "standard_scaler = StandardScaler()\n",
    "features_standard = standard_scaler.fit_transform(features)\n",
    "\n",
    "print(\"Min-Max Scaled (first 5 rows):\\n\", features_minmax[:5])\n",
    "print(\"Standardized (first 5 rows):\\n\", features_standard[:5])\n",
    "\n",
    "print(\"\\n--- Question 7: Handling Multiple Categorical Features ---\")\n",
    "# One-Hot Encoding 'sex' and 'embarked'\n",
    "multi_ohe = OneHotEncoder(sparse=False, drop='first')\n",
    "cat_features = df[['sex', 'embarked']]\n",
    "cat_encoded = multi_ohe.fit_transform(cat_features)\n",
    "print(\"One-Hot Encoded 'sex' & 'embarked' (first 5 rows):\\n\", cat_encoded[:5])\n",
    "\n",
    "print(\"\\n--- Question 8: Ordinal Encoding for Ranked Categories ---\")\n",
    "# 'pclass' as ordinal (1=1st class highest, 3=3rd class lowest)\n",
    "ordinal_map = {1: 3, 2: 2, 3: 1}  # reversing to rank: 1st=3, 2nd=2, 3rd=1 (example)\n",
    "df['pclass_ordinal'] = df['pclass'].map(ordinal_map)\n",
    "print(\"Ordinal encoded 'pclass' (first 10):\", df['pclass_ordinal'].head(10).tolist())\n",
    "\n",
    "print(\"\\n--- Question 9: Impact of Scaling on Different Algorithms ---\")\n",
    "# Prepare data\n",
    "X = df[['age', 'fare']]\n",
    "y = df['survived']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Decision Tree without scaling\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "dt_pred = dt.predict(X_test)\n",
    "print(\"Decision Tree accuracy (no scaling):\", accuracy_score(y_test, dt_pred))\n",
    "\n",
    "# SVM without scaling\n",
    "svm = SVC(random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "svm_pred = svm.predict(X_test)\n",
    "print(\"SVM accuracy (no scaling):\", accuracy_score(y_test, svm_pred))\n",
    "\n",
    "# Scale features with StandardScaler for SVM\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "svm_pred_scaled = svm.predict(X_test_scaled)\n",
    "print(\"SVM accuracy (with scaling):\", accuracy_score(y_test, svm_pred_scaled))\n",
    "\n",
    "print(\"\\n--- Question 10: Custom Transformations for High Cardinality Features ---\")\n",
    "\n",
    "class HighCardinalityEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, top_n=10):\n",
    "        self.top_n = top_n\n",
    "        self.top_categories_ = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.top_categories_ = X.value_counts().nlargest(self.top_n).index\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_transformed = X.apply(lambda x: x if x in self.top_categories_ else 'Other')\n",
    "        return pd.get_dummies(X_transformed)\n",
    "\n",
    "# Fix categorical dtype issue before filling NA for 'deck'\n",
    "if pd.api.types.is_categorical_dtype(df['deck']):\n",
    "    df['deck'] = df['deck'].cat.add_categories('Missing')\n",
    "\n",
    "df['deck'] = df['deck'].fillna('Missing')\n",
    "\n",
    "encoder = HighCardinalityEncoder(top_n=5)\n",
    "encoder.fit(df['deck'])\n",
    "encoded_deck = encoder.transform(df['deck'])\n",
    "\n",
    "print(encoded_deck.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
