{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating Data Cleaning in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "    Task: Basic Pipeline with Scaling\n",
    "1. Objective: Create a pipeline that scales numerical features in a dataset.\n",
    "2. Steps:\n",
    "    - Load a sample dataset with Pandas.\n",
    "    - Define a pipeline using Pipeline from sklearn.pipeline .\n",
    "    - Use StandardScaler to scale features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Training Data:\n",
      " [[-1.47393679  1.20365799 -1.56253475 -1.31260282]\n",
      " [-0.13307079  2.99237573 -1.27600637 -1.04563275]\n",
      " [ 1.08589829  0.08570939  0.38585821  0.28921757]\n",
      " [-1.23014297  0.75647855 -1.2187007  -1.31260282]\n",
      " [-1.7177306   0.30929911 -1.39061772 -1.31260282]]\n",
      "\n",
      "Scaled Test Data:\n",
      " [[ 0.35451684 -0.58505976  0.55777524  0.02224751]\n",
      " [-0.13307079  1.65083742 -1.16139502 -1.17911778]\n",
      " [ 2.30486738 -1.0322392   1.8185001   1.49058286]\n",
      " [ 0.23261993 -0.36147005  0.44316389  0.4227026 ]\n",
      " [ 1.2077952  -0.58505976  0.61508092  0.28921757]]\n"
     ]
    }
   ],
   "source": [
    "# Write your code from here\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load a sample dataset (Iris dataset)\n",
    "iris = load_iris()\n",
    "data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "target = iris.target\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a pipeline that scales features using StandardScaler\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler())  # Apply StandardScaler to the dataset\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data and transform the data\n",
    "X_train_scaled = pipeline.fit_transform(X_train)\n",
    "\n",
    "# Optionally, transform the test data with the same scaler\n",
    "X_test_scaled = pipeline.transform(X_test)\n",
    "\n",
    "# Output: Scaled train and test datasets\n",
    "print(\"Scaled Training Data:\\n\", X_train_scaled[:5])  # Print first 5 rows of scaled training data\n",
    "print(\"\\nScaled Test Data:\\n\", X_test_scaled[:5])  # Print first 5 rows of scaled test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Task: Pipeline with Imputation\n",
    "1. Objective: Automate data cleaning by handling missing values.\n",
    "2. Steps:\n",
    "    - Load a dataset with missing values.\n",
    "    - Define a pipeline to use SimpleImputer for filling missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data with Missing Values:\n",
      "    Age    Salary     Name\n",
      "0  25.0   50000.0     John\n",
      "1  30.0   60000.0    Alice\n",
      "2  35.0   70000.0      Bob\n",
      "3   NaN   80000.0  Charlie\n",
      "4  40.0       NaN    David\n",
      "5   NaN   90000.0      Eve\n",
      "6  45.0  100000.0    Frank\n",
      "\n",
      "Imputed Data:\n",
      "    Age    Salary     Name\n",
      "0  25.0   50000.0     John\n",
      "1  30.0   60000.0    Alice\n",
      "2  35.0   70000.0      Bob\n",
      "3  35.0   80000.0  Charlie\n",
      "4  40.0   75000.0    David\n",
      "5  35.0   90000.0      Eve\n",
      "6  45.0  100000.0    Frank\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Create a sample dataset with missing values\n",
    "data = {\n",
    "    'Age': [25, 30, 35, None, 40, None, 45],\n",
    "    'Salary': [50000, 60000, 70000, 80000, None, 90000, 100000],\n",
    "    'Name': ['John', 'Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Define which columns to process (numerical columns in this case)\n",
    "numeric_columns = ['Age', 'Salary']\n",
    "\n",
    "# Define a pipeline with a ColumnTransformer to handle imputation on numerical columns\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean'))  # Impute missing values with the mean of the column\n",
    "])\n",
    "\n",
    "# We will only apply the pipeline to numeric columns\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', pipeline, numeric_columns)\n",
    "    ], \n",
    "    remainder='passthrough'  # Leave non-numeric columns unchanged\n",
    ")\n",
    "\n",
    "# Fit the column transformer and transform the dataset\n",
    "df_imputed = column_transformer.fit_transform(df)\n",
    "\n",
    "# Convert the result back to a DataFrame, maintaining the original column names\n",
    "df_imputed_df = pd.DataFrame(df_imputed, columns=numeric_columns + [col for col in df.columns if col not in numeric_columns])\n",
    "\n",
    "# Output the original and imputed data\n",
    "print(\"Original Data with Missing Values:\")\n",
    "print(df)\n",
    "print(\"\\nImputed Data:\")\n",
    "print(df_imputed_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
